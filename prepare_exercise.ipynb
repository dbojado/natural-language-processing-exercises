{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in Glassdoor’s #1 Best Job in America.\n",
      "Data Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio, resulting in an explosion in Data Scientist positions across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen UTSA invest $70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\n",
      "Our program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "We focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in 14 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\n",
      "Applications are now open for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\n",
      "If you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original = acquire.get_article_text()\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoor’s #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. we’ve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing web dev program. we’re focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeup’s first data science cohort, which will start class on february 4, 2019. hurry – there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert all letters to lowercase\n",
    "article = original.lower()\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoors #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. weve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program. were focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning  regression; 6) supervised machine learning  classification; 7) unsupervised machine learning  clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeups first data science cohort, which will start class on february 4, 2019. hurry  there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove accented characters\n",
    "article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america\n",
      "data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry\n",
      "our program will be 18 weeks long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce\n",
      "we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning  regression 6 supervised machine learning  classification 7 unsupervised machine learning  clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development\n",
      "applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry  there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio\n",
      "if you want to learn about joining our program or hiring our graduates email datasciencecodeupcom\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove special characters\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rumors are true ! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator , with only 25 seats available ! This immersive program is one of a kind in San Antonio , and will help you land a job in Glassdoor ’ s #1 Best Job in America.\n",
      "Data Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio , resulting in an explosion in Data Scientist positions across companies like USAA , Accenture , Booz Allen Hamilton , and HEB. We ’ ve even seen UTSA invest $ 70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\n",
      "Our program will be 18 weeks long , full-time , hands-on , and project-based. Our curriculum development and instruction is led by Senior Data Scientist , Maggie Giust , who has worked at HEB , Capital Group , and Rackspace , along with input from dozens of practitioners and hiring partners. Students will work with real data sets , realistic problems , and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing , interviewing , and continuing education to prepare for a smooth transition to the workforce.\n",
      "We focus on applied data science for immediate impact and ROI in a business , which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We ’ re focusing on Data Science with Python , SQL , and ML , covered in 14 modules : 1 ) Fundamentals ; 2 ) Applied statistics ; 3 ) SQL ; 4 ) Python ; 5 ) Supervised machine learning – regression ; 6 ) Supervised machine learning – classification ; 7 ) Unsupervised machine learning – clustering ; 8 ) Time series analysis ; 9 ) Anomaly detection ; 10 ) Natural language processing ; 11 ) Distributed machine learning ; 12 ) Advanced topics ( deep learning , NoSQL , cloud deployment , etc. ) ; 13 ) Storytelling with data ; and 14 ) Domain expertise development.\n",
      "Applications are now open for Codeup ’ s first Data Science cohort , which will start class on February 4 , 2019. Hurry – there are only 25 seats available ! To further our mission of cultivating inclusive growth , scholarships will be available to women , minorities , LGBTQIA+ individuals , veterans , first responders , and people relocating to San Antonio.\n",
      "If you want to learn about joining our program or hiring our graduates , email datascience@codeup.com !\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "# Is the process of breaking down break words and any punctuation into discrete units\n",
    "\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(original, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming \n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "ps.stem('call'), ps.stem('called'), ps.stem('calling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career acceler with onli 25 seat avail thi immers program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in america data scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explos in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industri our program will be 18 week long fulltim handson and projectbas our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practition and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profession develop train in resum write interview and continu educ to prepar for a smooth transit to the workforc we focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarante just like our exist web dev program were focus on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain expertis develop applic are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclus growth scholarship will be avail to women minor lgbtqia individu veteran first respond and peopl reloc to san antonio if you want to learn about join our program or hire our graduat email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in article.split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data      13\n",
       "and       13\n",
       "to         9\n",
       "a          8\n",
       "in         8\n",
       "scienc     7\n",
       "our        7\n",
       "learn      6\n",
       "the        6\n",
       "of         6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/dbojado/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: studi -- lemma: study\n",
      "stem: studi -- lemma: study\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for word in 'study studies'.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumor are true the time ha arrived codeup ha officially opened application to our new data science career accelerator with only 25 seat available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution ha hit san antonio resulting in an explosion in data scientist position across company like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demand of this industry our program will be 18 week long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who ha worked at heb capital group and rackspace along with input from dozen of practitioner and hiring partner student will work with real data set realistic problem and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 module 1 fundamental 2 applied statistic 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topic deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development application are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seat available to further our mission of cultivating inclusive growth scholarship will be available to woman minority lgbtqia individual veteran first responder and people relocating to san antonio if you want to learn about joining our program or hiring our graduate email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "article_lemmatized = ' '.join(lemmas)\n",
    "\n",
    "print(article_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and        13\n",
       "data       13\n",
       "to          9\n",
       "in          8\n",
       "a           8\n",
       "our         7\n",
       "science     7\n",
       "will        6\n",
       "with        6\n",
       "of          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lemmas).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 122 stopwords\n",
      "---\n",
      "rumors true time arrived codeup officially opened applications new data science career accelerator 25 seats available immersive program one kind san antonio help land job glassdoors 1 best job america data science method providing actionable intelligence data data revolution hit san antonio resulting explosion data scientist positions across companies like usaa accenture booz allen hamilton heb weve even seen utsa invest 70 cybersecurity center school data science built program specifically meet growing demands industry program 18 weeks long fulltime handson projectbased curriculum development instruction led senior data scientist maggie giust worked heb capital group rackspace along input dozens practitioners hiring partners students work real data sets realistic problems entire data science pipeline collection deployment receive professional development training resume writing interviewing continuing education prepare smooth transition workforce focus applied data science immediate impact roi business back 6 month tuition refund guarantee like existing web dev program focusing data science python sql ml covered 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling data 14 domain expertise development applications open codeups first data science cohort start class february 4 2019 hurry 25 seats available mission cultivating inclusive growth scholarships available women minorities lgbtqia individuals veterans first responders people relocating san antonio want learn joining program hiring graduates email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "words = article.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')\n",
    "\n",
    "article_without_stopwords = ' '.join(filtered_words)\n",
    "\n",
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string): \n",
    "    '''\n",
    "    This function lowercases everything,normalizes unicode characters, and replace anything that is not a letter, number, whitespace or a single quote.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKC', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "#### This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove additional exclude_words.\n",
    "    stopword_list.extend(exclude_words)\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Add additional extra_words.\n",
    "    filtered_words.extend(extra_words)\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?    \n",
    "\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?    \n",
    "\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
